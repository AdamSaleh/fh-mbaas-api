var syncUtil = require('./util');
var util = require('util');
var async = require('async');

var syncStorage, dataHandlers, hashProvider;
var SYNC_UPDATE_TYPES = {
  APPLIED: 'applied',
  FAILED: 'failed',
  COLLISION: 'collisions'
};

function saveUpdate(datasetId, pendingChange, type, msg, callback) {
  var syncUpdateFields = {
    type: type,
    cuid: pendingChange.cuid,
    action: pendingChange.action,
    hash: pendingChange.hash,
    uid: pendingChange.uid,
    msg: msg
  };
  syncStorage.saveUpdate(datasetId, syncUpdateFields, callback);
}

function handleCollision(datasetId, metaData, pendingChange, dataHash, callback) {
  var collisionFields = {
    uid: pendingChange.uid,
    hash: dataHash,
    pre: pendingChange.pre,
    post: pendingChange.post,
    timestamp: pendingChange.timestamp
  };
  dataHandlers.handleCollision(datasetId, metaData, collisionFields, callback);
}

/**
 * Create the given pending change in the backend. 
 * It will always create the record in the backend.
 * @param {String} datasetId the dataset id
 * @param {Object} pendingChange the pending change. It should have the following fields
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be "delete"
 * @param {String} pendingChange.uid the unique id of the data record. This is a temp uid generated by the client and should be replaced by the real uid once the record is created.
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.post the record after change
 * @param {Function} callback
 */
function doCreate(datasetId, pendingChange, callback) {
  syncUtil.doLog(datasetId, 'verbose', 'CREATE Start');
  var record = pendingChange.post;
  var metaData = pendingChange.meta_data;
  dataHandlers.doCreate(datasetId, record, metaData, function(err, data){
    if (err) {
      syncUtil.doLog(datasetId, 'warn', 'CREATE Failed - : err = ' + util.inspect(err));
    } else {
      syncUtil.doLog(datasetId, 'info', 'CREATE Success - uid=' + data.uid);
      pendingChange.uid = data.uid;
    }
    return saveUpdate(datasetId, pendingChange, err? SYNC_UPDATE_TYPES.FAILED : SYNC_UPDATE_TYPES.APPLIED, err? util.inspect(err): null, callback);
  });
}

/**
 * Update the given pending change in the backend. 
 * It will only update the record if the hash value of the `pre` record matches the hash value of the record from backend.
 * Otherwise the change is either already applied, or a collision will be generated.
 * @param {String} datasetId the dataset id
 * @param {Object} pendingChange the pending change. It should have the following fields
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be "delete"
 * @param {String} pendingChange.uid the unique id of the data record
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.pre the record before change.
 * @param {Object} pendingChange.post the record after change
 * @param {Function} callback
 */
function doUpdate(datasetId, pendingChange, callback) {
  syncUtil.doLog(datasetId, 'verbose', 'UPDATE Start');
  var metaData = pendingChange.meta_data;
  var uid = pendingChange.uid;
  dataHandlers.doRead(datasetId, uid, metaData, function(err, data) {
    if (err) {
      syncUtil.doLog(datasetId, 'warn', 'READ for UPDATE Failed - uid=' + uid + ' : err = ' + util.inspect(err));
      return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.FAILED, util.inspect(err), callback);
    }
    syncUtil.doLog(datasetId, 'verbose', ' READ for UPDATE Success');
    syncUtil.doLog(datasetId, 'silly', 'READ for UPDATE Data : \n' + util.inspect(data));

    var preHash = hashProvider.recordHash(datasetId, pendingChange.pre);
    var dataHash = hashProvider.recordHash(datasetId, data);

    syncUtil.doLog(datasetId, 'verbose', 'UPDATE Hash Check ' + uid + ' (client :: dataStore) = ' + preHash + ' :: ' + dataHash);

    if (preHash === dataHash) {
      dataHandlers.doUpdate(datasetId, uid, pendingChange.post, metaData, function (err) {
        if (err) {
          syncUtil.doLog(datasetId, 'warn', 'UPDATE Failed - uid=' + uid + ' : err = ' + util.inspect(err));
        } else {
          syncUtil.doLog(datasetId, 'info', 'UPDATE Success - uid=' + uid + ' : hash = ' + dataHash);
        }
        return saveUpdate(datasetId, pendingChange, err? SYNC_UPDATE_TYPES.FAILED: SYNC_UPDATE_TYPES.APPLIED, err? util.inspect(err): null, callback);
      });
    } else {
      var postHash = hashProvider.recordHash(datasetId, pendingChange.post);
      if (postHash === dataHash) {
        // Update has already been applied
        syncUtil.doLog(datasetId, 'info', 'UPDATE Already Applied - uid=' + uid + ' : hash = ' + dataHash);
        return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.APPLIED, null, callback);
      }
      else {
        syncUtil.doLog(datasetId, 'warn', 'UPDATE COLLISION \n Pre record from client:\n' + util.inspect(syncUtil.sortObject(pendingChange.pre)) + '\n Current record from data store:\n' + util.inspect(syncUtil.sortObject(data)));
        handleCollision(datasetId, metaData, pendingChange, dataHash, function(err){
          if (err) {
            syncUtil.doLog(datasetId, 'warn', 'Failed to save collision uid =' + uid + ' : err = ' + util.inspect(err));
          }
          return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.COLLISION,  null, callback);
        });
      }
    }
  });
}

/**
 * Delete the given pending change from the backend. 
 * It will only delete the record if the hash value of the `pre` record matches the hash value of the record from backend.
 * Otherwise the change is either already applied, or a collision will be generated.
 * @param {String} datasetId the dataset id
 * @param {Object} pendingChange the pending change. It should have the following fields
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be "delete"
 * @param {String} pendingChange.uid the unique id of the data record
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.pre the record before change.
 * @param {Function} callback
 */
function doDelete(datasetId, pendingChange, callback) {
  syncUtil.doLog(datasetId, 'verbose', 'DELETE Start');
  var metaData = pendingChange.meta_data;
  var uid = pendingChange.uid;
  dataHandlers.doRead(datasetId, uid, metaData, function(err, data) {
    if (err) {
      syncUtil.doLog(datasetId, 'warn', 'READ for DELETE Failed - uid=' + uid + ' : err = ' + util.inspect(err));
      return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.FAILED, util.inspect(err), callback);
    }
    syncUtil.doLog(datasetId, 'verbose', ' READ for DELETE Success');
    syncUtil.doLog(datasetId, 'silly', ' READ for DELETE Data : \n' + util.inspect(data));

    var preHash = hashProvider.recordHash(datasetId, pendingChange.pre);
    var dataHash = hashProvider.recordHash(datasetId, data);

    syncUtil.doLog(datasetId, 'verbose', 'DELETE Hash Check ' + uid + ' (client :: dataStore) = ' + preHash + ' :: ' + dataHash);

    if (!dataHash) {
      //record has already been deleted
      syncUtil.doLog(datasetId, 'info', 'DELETE Already performed - uid=' + uid );
      return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.APPLIED, null, callback);
    }
    else {
      if (preHash === dataHash) {
        dataHandlers.doDelete(datasetId, uid, metaData, function(err) {
          if (err) {
            syncUtil.doLog(datasetId, 'warn', 'DELETE Failed - uid=' + uid + ' : err = ' + util.inspect(err));
          } else {
            syncUtil.doLog(datasetId, 'info', 'DELETE Success - uid=' + uid + ' : hash = ' + dataHash);
          }
          return saveUpdate(datasetId, pendingChange, err? SYNC_UPDATE_TYPES.FAILED: SYNC_UPDATE_TYPES.APPLIED, err? util.inspect(err): null, callback);
        });
      } else {
        syncUtil.doLog(datasetId, 'warn', 'DELETE COLLISION \n Pre record from client:\n' + util.inspect(syncUtil.sortObject(pendingChange.pre)) + '\n Current record from data store:\n' + util.inspect(syncUtil.sortObject(data)));
        handleCollision(datasetId, metaData, pendingChange, dataHash, function(err){
          if(err) {
            syncUtil.doLog(datasetId, 'warn', 'Failed to save collision uid =' + uid + ' : err = ' + util.inspect(err));
          }
          return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.COLLISION,  null, callback);
        });
      }
    }
  });
}

/**
 * apply the given pending change to the backend using the dataHandlers
 * @param {Object} pendingChange the pending change object
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be one of "create", "update" or "delete"
 * @param {String} pendingChange.uid the unique id of the data record
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.pre the record before change. Optional.
 * @param {Object} pendingChange.post the record after change. Optional. 
 * @param {Number} tries a counter to record how many times the given pending change has been executed
 * @param {Function} callback the callback function
 * @returns
 */
function applyPendingChange(pendingChange, tries, callback) {
  var datasetId = pendingChange.datasetId;
  if (!datasetId || !pendingChange.action || !pendingChange.uid || !pendingChange.cuid || !pendingChange.hash) {
    syncUtil.doLog(syncUtil.SYNC_LOGGER, "info", "invalid pendingChange request dropped :: item = " + util.inspect(pendingChange));
    return callback();
  }
  syncUtil.doLog(datasetId, 'silly', 'processPending :: item = ' + util.inspect(pendingChange));
  if (tries > 1) {
    //the pendingChange has been processed before but it didn't complete, most likely the process crashedd. Mark it as failed
    syncUtil.doLog(datasetId, 'silly', 'processPending failed :: tries = ' + tries + '  :: item = ' + util.inspect(pendingChange));
    return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.FAILED, "crashed", callback);
  }
  var action = pendingChange.action.toLowerCase();

  switch (action) {
    case "create":
      doCreate(datasetId, pendingChange, callback);
      break;
    case "update":
      doUpdate(datasetId, pendingChange, callback);
      break;
    case "delete":
      doDelete(datasetId, pendingChange, callback);
      break;
    default:
      syncUtil.doLog(datasetId, "info", "invalid pendingChange request dropped :: item = " + util.inspect(pendingChange));
      return callback();
  }
}

module.exports = function(syncStorageImpl, dataHandlersImpl, hashProviderImpl) {
  syncStorage = syncStorageImpl;
  dataHandlers = dataHandlersImpl;
  hashProvider = hashProviderImpl;
  return function(pendingChangeRequest, callback) {
    var pendingChange = pendingChangeRequest.payload;
    var tries = pendingChangeRequest.tries;
    return applyPendingChange(pendingChange, tries, callback);
  }
};

module.exports.SYNC_UPDATE_TYPES = SYNC_UPDATE_TYPES;